{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f2cf43025c0>\n",
      "+------------------------------------------------+\n",
      "|tweet_text                                      |\n",
      "+------------------------------------------------+\n",
      "|\"@flawarah \"\"How Haze Affects Milk Tea Brand.\"\"\"|\n",
      "|The haze are really bad                         |\n",
      "+------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "                                             tweet_text\n",
      "0      \"@flawarah \"\"How Haze Affects Milk Tea Brand.\"\"\"\n",
      "1                               The haze are really bad\n",
      "2     RT @allyxjackson: do yall understand just how ...\n",
      "3     RT @BRITgrlINDOfood: Standing on a bridge over...\n",
      "4        The haze is worse than when I arrived yester…\"\n",
      "...                                                 ...\n",
      "4941                          @knowyouskz Sometime okay\n",
      "4942                   @techinsider POLLUTION REDUCTION\n",
      "4943  this is still the funniest shit ever esgdjgash...\n",
      "4944  The weather and the haze also makes me feel th...\n",
      "4945                  @techinsider  POLLUTION REDUCTION\n",
      "\n",
      "[4946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # Call this only after findspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "#from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "#test sparkcontext\n",
    "print(spark)\n",
    "\n",
    "#https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html\n",
    "#entry point for spark to interact with spark's functions\n",
    "sparkSession = SparkSession.builder.appName(\"test_read_from_pg\").getOrCreate()\n",
    "\n",
    "#path to tweets text file in hadoop hdfs\n",
    "data=\"hdfs://namenode:9000/user/test/input/tweets_pg_export.txt\"\n",
    "\n",
    "#https://stackoverflow.com/questions/49471192/spark-2-3-0-read-text-file-with-header-option-not-working\n",
    "#load text file into Spark dataframes\n",
    "df_load = sparkSession.read.option(\"header\", \"true\").csv(data)\n",
    "\n",
    "#test and print 2 rows of Spark dataframe\n",
    "df_load.show(2, False)\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "#conver Spark dataframe into Pandas dataframe\n",
    "df_pandas = df_load.select(\"*\").toPandas()\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0      \"@flawarah \"\"how haze affects milk tea brand.\"\"\"\n",
      "1                               the haze are really bad\n",
      "2     rt @allyxjackson: do yall understand just how ...\n",
      "3     rt @britgrlindofood: standing on a bridge over...\n",
      "4        the haze is worse than when i arrived yester…\"\n",
      "...                                                 ...\n",
      "4941                          @knowyouskz sometime okay\n",
      "4942                   @techinsider pollution reduction\n",
      "4943  this is still the funniest shit ever esgdjgash...\n",
      "4944  the weather and the haze also makes me feel th...\n",
      "4945                  @techinsider  pollution reduction\n",
      "\n",
      "[4946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#change tweets into lowercase\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.lower()\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0                           how  affects milk tea brand\n",
      "1                                   the  are really bad\n",
      "2       do yall understand just how bad the  is ther...\n",
      "3       standing on a bridge overlooking the batangh...\n",
      "4             the  is worse than when i arrived yester…\n",
      "...                                                 ...\n",
      "4941                                      sometime okay\n",
      "4942                                pollution reduction\n",
      "4943  this is still the funniest shit ever esgdjgash...\n",
      "4944    the weather and the  also makes me feel thirsty\n",
      "4945                                pollution reduction\n",
      "\n",
      "[4946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#change tweets into lowercase\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.lower()\n",
    "#Removing RT retweet term\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.replace('rt', '')\n",
    "#Removing usernames\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'@\\w+', '', regex=True)\n",
    "#Removing url links\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'http\\S+', '', regex=True)\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'www.[^ ]+', '', regex=True)\n",
    "#remove next line \\n\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace('\\n',' ', regex=True)\n",
    "#remove numbers\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'[0-9]+', '', regex=True)\n",
    "#removing special characters\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]', '', regex=True)\n",
    "# Removing tweet topic\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.replace('haze', '')\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
