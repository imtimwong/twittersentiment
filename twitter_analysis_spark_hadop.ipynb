{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f1d935525f8>\n",
      "+------------------------------------------------+\n",
      "|tweet_text                                      |\n",
      "+------------------------------------------------+\n",
      "|\"@flawarah \"\"How Haze Affects Milk Tea Brand.\"\"\"|\n",
      "|The haze are really bad                         |\n",
      "+------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "                                             tweet_text\n",
      "0      \"@flawarah \"\"How Haze Affects Milk Tea Brand.\"\"\"\n",
      "1                               The haze are really bad\n",
      "2     RT @allyxjackson: do yall understand just how ...\n",
      "3     RT @BRITgrlINDOfood: Standing on a bridge over...\n",
      "4        The haze is worse than when I arrived yester…\"\n",
      "...                                                 ...\n",
      "4941                          @knowyouskz Sometime okay\n",
      "4942                   @techinsider POLLUTION REDUCTION\n",
      "4943  this is still the funniest shit ever esgdjgash...\n",
      "4944  The weather and the haze also makes me feel th...\n",
      "4945                  @techinsider  POLLUTION REDUCTION\n",
      "\n",
      "[4946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # Call this only after findspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "#from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "#test sparkcontext\n",
    "print(spark)\n",
    "\n",
    "#https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html\n",
    "#entry point for spark to interact with spark's functions\n",
    "sparkSession = SparkSession.builder.appName(\"test_read_from_pg\").getOrCreate()\n",
    "\n",
    "#path to tweets text file in hadoop hdfs\n",
    "data=\"hdfs://namenode:9000/user/test/input/tweets_pg_export.txt\"\n",
    "\n",
    "#https://stackoverflow.com/questions/49471192/spark-2-3-0-read-text-file-with-header-option-not-working\n",
    "#load text file into Spark dataframes\n",
    "df_load = sparkSession.read.option(\"header\", \"true\").csv(data)\n",
    "\n",
    "#test and print 2 rows of Spark dataframe\n",
    "df_load.show(2, False)\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "#conver Spark dataframe into Pandas dataframe\n",
    "df_pandas = df_load.select(\"*\").toPandas()\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0      \"@flawarah \"\"how haze affects milk tea brand.\"\"\"\n",
      "1                               the haze are really bad\n",
      "2     rt @allyxjackson: do yall understand just how ...\n",
      "3     rt @britgrlindofood: standing on a bridge over...\n",
      "4        the haze is worse than when i arrived yester…\"\n",
      "...                                                 ...\n",
      "4941                          @knowyouskz sometime okay\n",
      "4942                   @techinsider pollution reduction\n",
      "4943  this is still the funniest shit ever esgdjgash...\n",
      "4944  the weather and the haze also makes me feel th...\n",
      "4945                  @techinsider  pollution reduction\n",
      "\n",
      "[4946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#change tweets into lowercase\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.lower()\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0                           how  affects milk tea brand\n",
      "1                                   the  are really bad\n",
      "2       do yall understand just how bad the  is ther...\n",
      "3       standing on a bridge overlooking the batangh...\n",
      "4             the  is worse than when i arrived yester…\n",
      "...                                                 ...\n",
      "4941                                      sometime okay\n",
      "4942                                pollution reduction\n",
      "4943  this is still the funniest shit ever esgdjgash...\n",
      "4944    the weather and the  also makes me feel thirsty\n",
      "4945                                pollution reduction\n",
      "\n",
      "[4946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#change tweets into lowercase\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.lower()\n",
    "#Removing RT retweet term\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.replace('rt', '')\n",
    "#Removing usernames\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'@\\w+', '', regex=True)\n",
    "#Removing url links\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'http\\S+', '', regex=True)\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'www.[^ ]+', '', regex=True)\n",
    "#remove next line \\n\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace('\\n',' ', regex=True)\n",
    "#remove numbers\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'[0-9]+', '', regex=True)\n",
    "#removing special characters\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].replace(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]', '', regex=True)\n",
    "# Removing tweet topic\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].str.replace('haze', '')\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#need to manuall download 'punkt' before using this : nltk.download('punkt')\n",
    "from nltk.corpus import (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0                                affects milk tea brand\n",
      "1                                            really bad\n",
      "2     yall understand bad literally plant clouds clo...\n",
      "3     standing bridge overlooking batanghari river j...\n",
      "4                                 worse arrived yester…\n",
      "...                                                 ...\n",
      "4941                                      sometime okay\n",
      "4942                                pollution reduction\n",
      "4943             still funniest shit ever esgdjgashjdsa\n",
      "4944                    weather also makes feel thirsty\n",
      "4945                                pollution reduction\n",
      "\n",
      "[4946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "stop_words_eng = stopwords.words('english')\n",
    "#df['tweet_text'] = df['tweet_text'].str.lower()\n",
    "\n",
    "#lamda a type of hidden function or anonymous function written in one line instead of writing a new function\n",
    "#apply is used to apply the lamda function on one column\n",
    "#split the tweet using space in x.split() then check for if its not a stop word then join it together again with space\n",
    "#and move on to the next word of the tweet\n",
    "\n",
    "\n",
    "df_pandas['tweet_text'] = df_pandas['tweet_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words_eng)]))\n",
    "#print(df['tweet_text'].iloc[50])\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text  sentiment\n",
      "0                                affects milk tea brand        0.0\n",
      "1                                            really bad       -0.7\n",
      "2     yall understand bad literally plant clouds clo...       -0.7\n",
      "3     standing bridge overlooking batanghari river j...        0.0\n",
      "4                                 worse arrived yester…       -0.4\n",
      "...                                                 ...        ...\n",
      "4941                                      sometime okay        0.5\n",
      "4942                                pollution reduction        0.0\n",
      "4943             still funniest shit ever esgdjgashjdsa       -0.2\n",
      "4944                    weather also makes feel thirsty        0.0\n",
      "4945                                pollution reduction        0.0\n",
      "\n",
      "[4946 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#import for Natural language Processing(NLP) sentiment analysis library\n",
    "from textblob import TextBlob\n",
    "\n",
    "#https: // stackoverflow.com / questions / 54588807 / loop - to - retrieve - sentiment - analysis - in -pandas - core - series - series\n",
    "#add sentiment score into a new column in dataframe\n",
    "df_pandas['sentiment'] = df_pandas.tweet_text.apply(lambda tweet_text: TextBlob(tweet_text).sentiment.polarity)\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentimentanalysis():\n",
    "    \"\"\"\n",
    "    to convert sentiment score generated from TextBlob library into 1,-1 or 0 based on sentiment score.\n",
    "    \"\"\"\n",
    "\n",
    "    def analyse_sentiment(self, df):\n",
    "\n",
    "\n",
    "        sentiment = df\n",
    "\n",
    "        if sentiment > 0:\n",
    "            return 1\n",
    "        elif sentiment == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text  sentiment\n",
      "0                                affects milk tea brand          0\n",
      "1                                            really bad         -1\n",
      "2     yall understand bad literally plant clouds clo...         -1\n",
      "3     standing bridge overlooking batanghari river j...          0\n",
      "4                                 worse arrived yester…         -1\n",
      "...                                                 ...        ...\n",
      "4941                                      sometime okay          1\n",
      "4942                                pollution reduction          0\n",
      "4943             still funniest shit ever esgdjgashjdsa         -1\n",
      "4944                    weather also makes feel thirsty          0\n",
      "4945                                pollution reduction          0\n",
      "\n",
      "[4946 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "senti=sentimentanalysis()\n",
    "#convert sentiment score into 1(positive),-1(negative) or 0(neutral)\n",
    "df_pandas['sentiment'] = np.array([senti.analyse_sentiment(df_pandas) for df_pandas in df_pandas['sentiment']])\n",
    "\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this looks good so far :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
